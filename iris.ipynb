{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3a5409",
   "metadata": {},
   "source": [
    "# Iris Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2bf2b7",
   "metadata": {},
   "source": [
    "### Step 1 - Importing Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a8cb9",
   "metadata": {},
   "source": [
    "The first step before we do anything, will be to import the packages we need for this evaluation and data extractions. Packages are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d4c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb3c66e",
   "metadata": {},
   "source": [
    "As we can see, we still need Pandas to interact with the iris document as well as numpy for all our data manipulation \n",
    "\n",
    "Then, for all our plots, we'll need matplotlib and seaborn (While seaborn can do what matplotlib does, I started off with matplotlib and only at the end, did I move to seaborn as it was the easiest way to achieve a pairplot)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d145ce4",
   "metadata": {},
   "source": [
    "### Step 2 - Reading our Data Set and organising it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475912e5",
   "metadata": {},
   "source": [
    "The Iris data set comes with no column names and using Pandas, we have no way of actually knowing what columns are what. Through the names txt file, we know what the attributes are but we need to name them in order to work with them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f5cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc168d66",
   "metadata": {},
   "source": [
    "After our columns have been named, we go ahead and open the data set in our folder with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b560093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.data', names=column_names)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f379a1",
   "metadata": {},
   "source": [
    "Now, it's way more clearer. I had some issues here because all the documentation I was checking was about csv files, not data files. It was Chatgpt that explained to me that I can apply the same reading method to data files as I would to csv files.\n",
    "\n",
    "__Prompt__ - I have iris.data what file format is that?\n",
    "\n",
    "__Chatgpt response__: \n",
    "_The iris.data file is essentially a plain text file formatted as comma-separated values (CSV)._\n",
    "_Even though it doesn't have a \".csv\" extension, it follows the same structure: each row represents a record, and the values are separated by commas._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f055db",
   "metadata": {},
   "source": [
    "We are also going to need to go ahead and assign all those values in each column to their own variables. This will make it easier to work with each feature later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecab1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_length = df['sepal_length']\n",
    "sepal_width  = df['sepal_width']\n",
    "petal_length = df['petal_length']\n",
    "petal_width  = df['petal_width']\n",
    "species      = df['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee0707b",
   "metadata": {},
   "source": [
    "### Step 3 - Outputting Summaries of variables\n",
    "#### Step 3.1 - Fixing df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981110c7",
   "metadata": {},
   "source": [
    "This was the hardest part of the project for me. With Pandas, we have access to a very handy function called .describe() which makes our lives incredibly easy when it comes\n",
    "to getting statistics and values out of the data set. \n",
    "\n",
    "The main issue is the presentation. I don't want the median displayed as 50%. By default, Pandas displays it like this. Unfortunately according to the pandas documentation, df.describe(percentiles=[]) still includes the 50%. this is more of a stylistic choice but I think we need to solve it. \n",
    "\n",
    "I then went ahead and found out about select_dtypes and .agg to basically get just the numbers, seeing that we're more interested in that rather than the species at the moment. \n",
    "and getting the aggregates of what I want. So, we first get the numeric variables only and get the aggregates of what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "numeric_summary = numeric_df.agg(['count', 'mean', 'std', 'min', 'median', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e88f9cf",
   "metadata": {},
   "source": [
    "#### Step 3.2 - Creating the Summary txt files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19212a0a",
   "metadata": {},
   "source": [
    "Now that this is done, we'll go ahead and create a for loop to iterate through each column and assign each variable to its own named summary txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c759c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    file_name = f\"{col}_summary.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b48c163",
   "metadata": {},
   "source": [
    "Next, within this loop, we're going to use the is_numeric_dtype to search each column if they are numeric. This is because we have the species which are non numerical.\n",
    "This if statement will search for the numeric values and assing them to a variable using the agg function used before and if there is a string in there (species names)\n",
    "It will do the same and count their values with value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c8cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pd.api.types.is_numeric_dtype(df[col]):\n",
    "    col_summary = df[col].agg(['count', 'mean', 'std', 'min', 'median', 'max'])\n",
    "else:\n",
    "    col_summary = df[col].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c674dac0",
   "metadata": {},
   "source": [
    "We then move to the txt generation part. We open file name as a write file and just write in there the summaries that we're organised before in the if statement.\n",
    "I struggled with this because I was only getting the species to their own txt file until I realised that the reason for that was due to all of the above not being inside the for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8537c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, \"w\") as file:\n",
    "    file.write(col_summary.to_string())\n",
    "    \n",
    "print(f\"Summary for {col} has been written to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36861c7f",
   "metadata": {},
   "source": [
    "#### Step 4 - Creating the Plots (Histograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385005d7",
   "metadata": {},
   "source": [
    "So, for the plot I wasn't really sure how to approach it. Should we get each variable only? Or maybe each variable accross all three species? After some research, \n",
    "I found a very interesting article that showcased the different variables with all plotted on top of each other in histograms. This was what I decided to go for.\n",
    "\n",
    "The article used Seaborn so I went ahead and imported that.\n",
    "We first create our variables for each and we search the dataframe for their respective species lines via the loc function and check if the species\n",
    "matches the species we've chosen. \n",
    "\n",
    "I ran into several problems, particularly when it comes to the Sepal_width. I discovered seaborns own built in palette and after several tries I settled with colorblind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cb66b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"muted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2b005",
   "metadata": {},
   "source": [
    "After this is done, we go ahead with Seaborn itself, getting our df (dataset), our hue, which would help us know that all species need to have different colours,\n",
    "and the height which I left as the original.\n",
    "\n",
    "Next comes the histplot itself. We get each variable as defined, followed by the number of bins (I went with 10 after several tries) and opacity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4fb846",
   "metadata": {},
   "outputs": [],
   "source": [
    "petal_length_histogram = sns.FacetGrid(df, hue=\"species\", height=3).map(sns.histplot, \"petal_length\", bins=10, alpha=0.5).add_legend()\n",
    "petal_width_histogram = sns.FacetGrid(df, hue=\"species\",  height=3).map(sns.histplot, \"petal_width\", bins=10, alpha=0.5).add_legend()\n",
    "sepal_length_histogram = sns.FacetGrid(df, hue=\"species\",  height=3).map(sns.histplot, \"sepal_length\", bins=10, alpha=0.5).add_legend()\n",
    "sepal_width_histogram = sns.FacetGrid(df, hue=\"species\",  height=3).map(sns.histplot, \"sepal_width\", bins=10, alpha=0.5).add_legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0864f89f",
   "metadata": {},
   "source": [
    "Finally we saved all of the above to different pngs. ChatGPT<sup>12</sup> helped me here and remminded me that the above code needed to be saved to a specific variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7534f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "petal_length_histogram.savefig(\"petal_length_histogram.png\", bbox_inches='tight')\n",
    "petal_width_histogram.savefig(\"petal_width_histogram.png\", bbox_inches='tight')\n",
    "sepal_length_histogram.savefig(\"sepal_length_histogram.png\", bbox_inches='tight')\n",
    "sepal_width_histogram.savefig(\"sepal_width_histogram.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb8de3",
   "metadata": {},
   "source": [
    "#### Step 5 - Creating the Plots Part 2 (Scatterplots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae970f",
   "metadata": {},
   "source": [
    "Now, for the scatterplot, we need to once again decide on what colours we're going to use here. Since we've already decided on \"colorblind\"\n",
    "for the histograms, let's keep that one for consistency and pull from that with seaborn.\n",
    "By following the documentation inthe seaborn website, we just need to pull from our data(df), assign our x and y which have already been defined previously and choose the palette. \n",
    ">\n",
    "Afterwards, we make sure that we just make sure we also export that to its respective png file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f4faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_scatterplot = sns.scatterplot(data=df, x=\"sepal_length\", y=\"sepal_width\", hue=\"species\", palette=\"colorblind\")\n",
    "plt.savefig(\"sepal_scatterplot.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1bdb6f",
   "metadata": {},
   "source": [
    "We repeat the same for the petals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d87db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "petal_scatterplot = sns.scatterplot(data=df, x=\"petal_length\", y=\"petal_width\", hue=\"species\", palette=\"colorblind\")\n",
    "plt.savefig(\"petal_scatterplot.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f3d9f",
   "metadata": {},
   "source": [
    "#### Step 6 - Extra (Pairplots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed24f1b",
   "metadata": {},
   "source": [
    "One final analysis I found worth using was the pairplot. As it show cases the various relationships accross all variables, while more complete, it's also\n",
    "more overwhelming to the eyes, making minute or specific detail finding more difficult. I considered using the histogram fro the diagonal but after several \n",
    "attepmts at trying to make it look less \"squished\" I eventually settled with leaving the default KDE since we're already exported the histograms anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f31caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_plot = sns.pairplot(df, hue=\"species\")\n",
    "pair_plot.savefig(\"pairplot.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9563a20",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. https://realpython.com/pandas-dataframe/#filtering-data - On filtering the data for specific columns.\n",
    "\n",
    "2. https://medium.com/@SamTaylor92/data-analysis-python-exploring-a-dataset-summary-statistics-afc7a690ec96 - On approaching the Iris Dataset.\n",
    "\n",
    "3. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html - On selecting specific types of data (e.g numbers).\n",
    "\n",
    "4. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html - On the aggregate function to bypass the Median showcasing problem.\n",
    "\n",
    "5. https://www.w3schools.com/python/python_file_write.asp - On writing files with Python.\n",
    "\n",
    "6. https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_numeric_dtype.html - Documentation on api.types that shows us how to check for specific values. Very important since one of the features (\"species\") doesn't have any agg values.\n",
    "\n",
    "7. https://seaborn.pydata.org/generated/seaborn.FacetGrid.html - On the basics of Seaborn and getting and getting our data onto the plot.\n",
    "\n",
    "8. https://medium.com/@nirajan.acharya777/exploratory-data-analysis-of-iris-dataset-9c0df76771df - On the various ways of showcasing the Iris Dataset and possible correlations.\n",
    "\n",
    "9. https://matplotlib.org/stable/users/explain/colors/colors.html - On the many colour keywords for the plots.\n",
    "\n",
    "10. https://medium.com/@maxmarkovvision/optimal-number-of-bins-for-histograms-3d7c48086fde - A study on the most appropriate number of bins for histograms.\n",
    "\n",
    "11. https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html - On saving plots as png files.\n",
    "\n",
    "12. __ChatGPT:__ _\"The best approach is to assign each FacetGrid to a variable, save its figure immediately with the savefig method (or plt.savefig using its .fig attribute), \n",
    "and then close that figure before moving on. This ensures that each plot is saved independently without overlapping.\"_ \n",
    "\n",
    "13. https://seaborn.pydata.org/generated/seaborn.scatterplot.html - On making scatterplots with seaborn\n",
    "\n",
    "14. https://seaborn.pydata.org/generated/seaborn.pairplot.html - On making pairplots with seaborn\n",
    "\n",
    "15. https://www.analyticsvidhya.com/blog/2024/02/pair-plots-in-machine-learning/ - On reading pairplots\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f9638",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
