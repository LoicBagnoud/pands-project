{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3a5409",
   "metadata": {},
   "source": [
    "# Iris Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2bf2b7",
   "metadata": {},
   "source": [
    "### Step 1 - Importing Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a8cb9",
   "metadata": {},
   "source": [
    "The first step before we do anything, will be to import the packages we need for this evaluation and data extractions. Packages are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d4c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb3c66e",
   "metadata": {},
   "source": [
    "As we can see, we still need Pandas to interact with the iris document as well as numpy for all our data manipulation \n",
    "\n",
    "Then, for all our plots, we'll need matplotlib and seaborn (While seaborn can do what matplotlib does, I started off with matplotlib and only at the end, did I move to seaborn as it was the easiest way to achieve a pairplot)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d145ce4",
   "metadata": {},
   "source": [
    "### Step 2 - Reading our Data Set and organising it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475912e5",
   "metadata": {},
   "source": [
    "The Iris data set comes with no column names and using Pandas, we have no way of actually knowing what columns are what. Through the names txt file, we know what the attributes are but we need to name them in order to work with them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f5cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc168d66",
   "metadata": {},
   "source": [
    "After our columns have been named, we go ahead and open the data set in our folder with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b560093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.data', names=column_names)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f379a1",
   "metadata": {},
   "source": [
    "Now, it's way more clearer. I had some issues here because all the documentation I was checking was about csv files, not data files. It was Chatgpt that explained to me that I can apply the same reading method to data files as I would to csv files.\n",
    "\n",
    "__Prompt__ - I have iris.data what file format is that?\n",
    "\n",
    "__Chatgpt response__: \n",
    "_The iris.data file is essentially a plain text file formatted as comma-separated values (CSV)._\n",
    "_Even though it doesn't have a \".csv\" extension, it follows the same structure: each row represents a record, and the values are separated by commas._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f055db",
   "metadata": {},
   "source": [
    "We are also going to need to go ahead and assign all those values in each column to their own variables. This will make it easier to work with each feature later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecab1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_length = df['sepal_length']\n",
    "sepal_width  = df['sepal_width']\n",
    "petal_length = df['petal_length']\n",
    "petal_width  = df['petal_width']\n",
    "species      = df['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee0707b",
   "metadata": {},
   "source": [
    "### Step 3 - Outputting Summaries of variables\n",
    "#### Step 3.1 - Fixing df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981110c7",
   "metadata": {},
   "source": [
    "This was the hardest part of the project for me. With Pandas, we have access to a very handy function called .describe() which makes our lives incredibly easy when it comes\n",
    "to getting statistics and values out of the data set. \n",
    "\n",
    "The main issue is the presentation. I don't want the median displayed as 50%. By default, Pandas displays it like this. Unfortunately according to the pandas documentation, df.describe(percentiles=[]) still includes the 50%. this is more of a stylistic choice but I think we need to solve it. \n",
    "\n",
    "I then went ahead and found out about select_dtypes to basically get just the numbers, seeing that we're more interested in that rather than the species at the moment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=['number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d4980b",
   "metadata": {},
   "source": [
    "This basically creates a variable called \"numeric_df\" and assigns it the function select_dtypes that should be able to specify only the columns with numeric data types (such as integers and floats). \n",
    ">\n",
    "In other words, it scans the entire DataFrame (df, which contains the Iris dataset) and filters out only those columns that contain numerical values, ignoring any columns with non-numeric data (like strings or categories, such as the species column)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977c6b29",
   "metadata": {},
   "source": [
    "Next, we move forward to getting our actual values, for this, we're gonna use the following functions from numpy:\n",
    ">\n",
    "np.mean\n",
    "\n",
    "np.min\n",
    "\n",
    "np.max\n",
    "\n",
    "np.std\n",
    "\n",
    "np.median\n",
    "\n",
    "Each of these will provide us with what df.describe would provide with one line of code, but instead of showing us the median as 50%, we can actually use this to call our stats what we want and organise them how we wish. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e88f9cf",
   "metadata": {},
   "source": [
    "#### Step 3.2 - Creating the Summary txt files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116755ca",
   "metadata": {},
   "source": [
    "Now, for the actual creationg of the txt, I'm going to break this code down and I'll explain it in comments what is actually happening here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e42187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin by opening or \"creating\" a txt file called summary. We will call it f. The With makes sure that we don't need to close the file afterwards,\n",
    "# it should close automatically. \n",
    "with open(\"summary.txt\", \"w\") as f:\n",
    "\n",
    "# Now, we're going to iterate through the columns. This for loop will iterate through each column in the numeric.df variable we have created above that should only\n",
    "# contain numeric values.\n",
    "    for column in numeric_df.columns:\n",
    "\n",
    "# Next, we will extract all the values from the current column into a Numpy array called \"data\".\n",
    "        data = numeric_df[column].values\n",
    "\n",
    "# Now, we can go ahead and write into the txt file what we want. We'll write statistics for the first column (whatever it is, it should be Sepal_length), and then we get for that column,\n",
    "# the various stats, 2 decimal places up, and we will repeat this same code and go through this loop as many times as there are columns because of the loop.\n",
    "        f.write(f\"Statistics for {column}:\\n\")\n",
    "        f.write(f\"  Mean: {np.mean(data):.2f}\\n\")\n",
    "        f.write(f\"  Minima: {np.min(data):.2f}\\n\")\n",
    "        f.write(f\"  Maxima: {np.max(data):.2f}\\n\")\n",
    "        f.write(f\"  Standard Deviation: {np.std(data):.2f}\\n\")\n",
    "        f.write(f\"  Median: {np.median(data):.2f}\\n\")\n",
    "        f.write(\"\\n\")  \n",
    "\n",
    "# We'll finish it all with a print to just signal to whoever ran the code that the summary txt was successfully generated. \n",
    "print(\"Summary exported to iris_numeric_summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ea679",
   "metadata": {},
   "source": [
    "With our txt file now created with all our statistics, we can try and extract some analysis. \n",
    "\n",
    "```\n",
    "Statistics for sepal_length:\n",
    "  Mean: 5.84\n",
    "  Minima: 4.30\n",
    "  Maxima: 7.90\n",
    "  Standard Deviation: 0.83\n",
    "  Median: 5.80\n",
    "\n",
    "Statistics for sepal_width:\n",
    "  Mean: 3.05\n",
    "  Minima: 2.00\n",
    "  Maxima: 4.40\n",
    "  Standard Deviation: 0.43\n",
    "  Median: 3.00\n",
    "\n",
    "Statistics for petal_length:\n",
    "  Mean: 3.76\n",
    "  Minima: 1.00\n",
    "  Maxima: 6.90\n",
    "  Standard Deviation: 1.76\n",
    "  Median: 4.35\n",
    "\n",
    "Statistics for petal_width:\n",
    "  Mean: 1.20\n",
    "  Minima: 0.10\n",
    "  Maxima: 2.50\n",
    "  Standard Deviation: 0.76\n",
    "  Median: 1.30\n",
    "```\n",
    "\n",
    "From the summaries we have extracted, we can see that overall, everything falls very much in line with what we expected. With nothing particularly egregious about it but we do notice that some features contain a higher Standard Deviation than others. For instance, petal length has a standard deviation of 1.76, indicating greater spread across the entire dataset. In contrast, sepal width shows much less variation and appears more uniform across species.\n",
    ">\n",
    "This is a huge number and already highlights that some species (we're not sure which ones yet, but we could infer Petal Length) are driving that standard deviation up. In other words, there are outliers present in those features that are not shared accross the species and given that number, we can clearly see that some gap between the species is vast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36861c7f",
   "metadata": {},
   "source": [
    "#### Step 4 - Creating the Plots (Histograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385005d7",
   "metadata": {},
   "source": [
    "So, for the plot I wasn't really sure how to approach it. Should we get each variable only? Or maybe each variable accross all three species? After some research, \n",
    "I found a very interesting article that showcased the different variables with all plotted on top of each other in histograms. This was what I decided to go for.\n",
    "\n",
    "The article used Seaborn so I went ahead and imported that.\n",
    "We first create our variables for each and we search the dataframe for their respective species lines via the loc function and check if the species\n",
    "matches the species we've chosen. \n",
    "\n",
    "I ran into several problems, particularly when it comes to the Sepal_width. I discovered seaborns own built in palette and after several tries I settled with colorblind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cb66b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"muted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2b005",
   "metadata": {},
   "source": [
    "After this is done, we go ahead with Seaborn itself, getting our df (dataset), our hue, which would help us know that all species need to have different colours,\n",
    "and the height which I left as the original.\n",
    "\n",
    "Next comes the histplot itself. We get each variable as defined, followed by the number of bins (I went with 10 after several tries) and opacity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4fb846",
   "metadata": {},
   "outputs": [],
   "source": [
    "petal_length_histogram = sns.FacetGrid(df, hue=\"species\", height=3).map(sns.histplot, \"petal_length\", bins=10, alpha=0.5).add_legend()\n",
    "petal_width_histogram = sns.FacetGrid(df, hue=\"species\",  height=3).map(sns.histplot, \"petal_width\", bins=10, alpha=0.5).add_legend()\n",
    "sepal_length_histogram = sns.FacetGrid(df, hue=\"species\",  height=3).map(sns.histplot, \"sepal_length\", bins=10, alpha=0.5).add_legend()\n",
    "sepal_width_histogram = sns.FacetGrid(df, hue=\"species\",  height=3).map(sns.histplot, \"sepal_width\", bins=10, alpha=0.5).add_legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0864f89f",
   "metadata": {},
   "source": [
    "Finally we saved all of the above to different pngs. ChatGPT<sup>12</sup> helped me here and remminded me that the above code needed to be saved to a specific variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7534f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "petal_length_histogram.savefig(\"petal_length_histogram.png\", bbox_inches='tight')\n",
    "petal_width_histogram.savefig(\"petal_width_histogram.png\", bbox_inches='tight')\n",
    "sepal_length_histogram.savefig(\"sepal_length_histogram.png\", bbox_inches='tight')\n",
    "sepal_width_histogram.savefig(\"sepal_width_histogram.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb8de3",
   "metadata": {},
   "source": [
    "#### Step 5 - Creating the Plots Part 2 (Scatterplots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae970f",
   "metadata": {},
   "source": [
    "Now, for the scatterplot, we need to once again decide on what colours we're going to use here. Since we've already decided on \"colorblind\"\n",
    "for the histograms, let's keep that one for consistency and pull from that with seaborn.\n",
    "By following the documentation inthe seaborn website, we just need to pull from our data(df), assign our x and y which have already been defined previously and choose the palette. \n",
    ">\n",
    "Afterwards, we make sure that we just make sure we also export that to its respective png file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f4faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_scatterplot = sns.scatterplot(data=df, x=\"sepal_length\", y=\"sepal_width\", hue=\"species\", palette=\"colorblind\")\n",
    "plt.savefig(\"sepal_scatterplot.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1bdb6f",
   "metadata": {},
   "source": [
    "We repeat the same for the petals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d87db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "petal_scatterplot = sns.scatterplot(data=df, x=\"petal_length\", y=\"petal_width\", hue=\"species\", palette=\"colorblind\")\n",
    "plt.savefig(\"petal_scatterplot.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f3d9f",
   "metadata": {},
   "source": [
    "#### Step 6 - Extra (Pairplots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed24f1b",
   "metadata": {},
   "source": [
    "One final analysis I found worth using was the pairplot. As it show cases the various relationships accross all variables, while more complete, it's also\n",
    "more overwhelming to the eyes, making minute or specific detail finding more difficult. I considered using the histogram fro the diagonal but after several \n",
    "attepmts at trying to make it look less \"squished\" I eventually settled with leaving the default KDE since we're already exported the histograms anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f31caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_plot = sns.pairplot(df, hue=\"species\")\n",
    "pair_plot.savefig(\"pairplot.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9563a20",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. https://realpython.com/pandas-dataframe/#filtering-data - On filtering the data for specific columns.\n",
    "\n",
    "2. https://medium.com/@SamTaylor92/data-analysis-python-exploring-a-dataset-summary-statistics-afc7a690ec96 - On approaching the Iris Dataset.\n",
    "\n",
    "3. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html - On selecting specific types of data (e.g numbers).\n",
    "\n",
    "4. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html - On the aggregate function to bypass the Median showcasing problem.\n",
    "\n",
    "5. https://www.w3schools.com/python/python_file_write.asp - On writing files with Python.\n",
    "\n",
    "6. https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_numeric_dtype.html - Documentation on api.types that shows us how to check for specific values. Very important since one of the features (\"species\") doesn't have any agg values.\n",
    "\n",
    "7. https://seaborn.pydata.org/generated/seaborn.FacetGrid.html - On the basics of Seaborn and getting and getting our data onto the plot.\n",
    "\n",
    "8. https://medium.com/@nirajan.acharya777/exploratory-data-analysis-of-iris-dataset-9c0df76771df - On the various ways of showcasing the Iris Dataset and possible correlations.\n",
    "\n",
    "9. https://matplotlib.org/stable/users/explain/colors/colors.html - On the many colour keywords for the plots.\n",
    "\n",
    "10. https://medium.com/@maxmarkovvision/optimal-number-of-bins-for-histograms-3d7c48086fde - A study on the most appropriate number of bins for histograms.\n",
    "\n",
    "11. https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html - On saving plots as png files.\n",
    "\n",
    "12. __ChatGPT:__ _\"The best approach is to assign each FacetGrid to a variable, save its figure immediately with the savefig method (or plt.savefig using its .fig attribute), \n",
    "and then close that figure before moving on. This ensures that each plot is saved independently without overlapping.\"_ \n",
    "\n",
    "13. https://seaborn.pydata.org/generated/seaborn.scatterplot.html - On making scatterplots with seaborn\n",
    "\n",
    "14. https://seaborn.pydata.org/generated/seaborn.pairplot.html - On making pairplots with seaborn\n",
    "\n",
    "15. https://www.analyticsvidhya.com/blog/2024/02/pair-plots-in-machine-learning/ - On reading pairplots\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f9638",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
